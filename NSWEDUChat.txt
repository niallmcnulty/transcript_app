Welcome to the AI and Education podcast. How are you doing, Ray? Are you ready for this next series? I am excited, Dan, because just in case people missed it, last series, the last episode was the end of series eight, which was all about assessment. That's the crisis that AI created. And the research that we've picked up in the news episodes as well, a lot of that talks about assessment and teachers are always talking about assessment as well and the way they can use AI in the classroom for assessment. So it seemed to be really relevant and I hope that brought some really good stories together, especially the last episode. We got to talk to some really interesting people about the topic. I don't think we came to a conclusion in the sense of we know that assessment has to change. We've had some great discussions about what it might look like in the future. But I think there isn't an obvious path forward at the moment. We're still in that stage of discovering what the path is. But some brilliant advice about how to cope with the transition period. But now, Dan, we're on to series nine. This is the first episode of series nine. And this is all about AI tutors, Dan. So this is the opportunity to match the challenge of assessment, the opportunity around AI tutors. And I want to be incredibly optimistic in this series. Absolutely. And personalization is something that's been on the agenda for teachers for years and years and years since I started teaching. And the amount of different needs you've got in the classroom, the amount of students from different backgrounds in the classroom, personalization seems to be one of those panaceas that we've never really been able to deliver. Even with the lots of advances in technology, we've never really seemed to have the technology to deliver that exactly in the classroom to the individuals at the point of learning. So Dan, you used this phrase last time I saw you talking at an event. You talked about the two sigma problem. Oh, yes. Tell me about it. Well, the two sigma problem is quite famous and a lot of people are talking about it. Essentially, when you're looking at the interventions you can give to students, what the research says, according to the two sigma problem, when you personalize and tutor people individually, one on one, then you can get basically two standard deviations of difference in your kind of output. So basically, you're going to have a massive effect on students' outcomes if you're tutoring people individually. But essentially, what I'm saying is, if you can be there and be a point of presence tutoring somebody individually, that has a better effect on learning than teaching people in a group. So the two sigma problem was the research paper that was produced by Bloom. He was busy, wasn't he? He was doing two sigma and taxonomies at the same time. It's from 1984. So it's 40 years ago. And the research said, yes, you get this massive increase if a student can have a tutor. And it's been long believed now that the solution to get the jump in education performance is to be able to provide a tutor for a student. So I said, I'm going to be positive on this series. And so my positivity is this opportunity to provide AI tutors and all that kind of stuff that we're seeing is about how do we pair the technology with the pedagogy? How do we make sure that this isn't tech companies going, we are going to solve everybody's problem, but actually it's led out of an education lens and perspective? That's right. In this series, you've interviewed quite a lot of people who are really, really influential. In this actual episode, we've got Michelle, Michael and Dan Hart from the New South Wales Department of Education. And it's a great episode because we really get into the nitty gritty of their tutor. And obviously the New South Wales Department is really large. We've got other guests as well coming in as well from around the globe, haven't we, Ray? Yeah, we've got a round the world ticket for this series, Dan, because we've already recorded almost half the episodes. So we've got Anthony England from just up the road from us at Pimble Ladies College. We've got Amanda Bickerstaff in the US. We've got Rose Lucking from the UK. We keep the trip going, we'll end up with Owen Flattery in New Zealand. And then back in Australia, we'll be talking to Phil Dawson and Pip Cleaves, educators rather than technologists. And I think that's where the conversation really needs to focus is, great, let's talk about the AI bit, but it's the educational conversation, because with personalisation and AI tutors, there's the real risk that technology becomes. the driving force and it's got to be about pedagogy and education. It's got to be the thing that drives the technology. And the heartwarming story here coming up today in this episode obviously revolves around public education and a really large system trialling personalisation and tutors and in a real thoughtful way and I can't wait for the listeners to hear this story. Brilliant so as we dive into it probably our phrase for the last series was AI detectors don't work. I think our phrase for this series is AI should not be used to replace teachers and let's remember that as we go into all these conversations about personalisation and tutors. Brilliant. Okay let's go and listen to Michelle and Dan. Welcome to the AI education podcast. Today we continue our search Ray for the holy grail of AI education. Oh my god we're searching for the holy grail? Are we turning into Monty Python Dan? We must be with the two knights that say knee this morning. We are, we're very lucky to be joined by the fantastic Michelle Michael and Dan Hart from the New South Wales Department of Education which is one of the larger providers of public education in the world. Michelle's the Director of Education Support and Rural Initiatives and the Director of New South Wales Gen AI and Teaching and Learning in the department and Dan Hart's the Head of AI and was the Principal Data Integration Manager for the New South Wales Department. So hello and welcome to you both on our little podcast here. Good morning. Hi Dan, hi Ray. Michelle I can imagine what your world is like if you're in charge of remote and rural because when we moved to Australia 13 years ago the first time we flew back to the UK after about an hour and a half on the plane my kids said to me are we nearly there yet? I didn't have the heart to tell them that we had 24 hours still ahead of us but I did say no we've not even left the state of New South Wales yet. Yeah that's pretty accurate it's a pretty big department and I think we'll get into some of those stats in a little while but yeah it's an enormous place. Absolutely so from a department so when we think about the Department of Education obviously my kids go to a New South Wales Department school, yay! The vastness of the state and the actual school system is something to behold so can you share some statistics about the scale and the challenges you've got across the New South Wales Education Department Michelle? It warms my heart to hear that you send your children to a New South Wales Government school. I also send my children to a New South Wales Government school so we champion and nurture that lifelong learning for all students regardless of their background and location but DOE size we're the largest education provider in Australia we've got more than 800,000 students more than 2,200 schools we've got 100,000 employees and every day in terms of the technology more than 400,000 devices connect to the network we've got 8 million portal logins each month 14 million single sign-on logins to DOE each month by students so Dan and his team over in ITD or ITD colleagues that support that work they have a lot on their plates and when they log on to our network they're then able to use some of the work that we have there including some of the Microsoft suite and the Google suites and so on so a huge huge system. Yeah it's and in education I think sometimes people don't realise scale when you look at a large business say one like Microsoft we know in the year that scale it's just phenomenal to the work you all do to kind of really just just people logging into that portal the statistics are mad the single sign-on connections it's just absolutely unreal really so thank you for all the work you're doing in that area. Why do you actually start this journey for AI in education in New South Wales Department then? Dan Hart did you want to jump into that because I didn't know Dan until about 18 months ago Dan and I had never met we'd worked in the department and like I said there's around 100,000 employees and Dan and I were two different ones yeah yeah it landed when there was some conversations around New York and ChatGPT obviously had landed and there was some restrictions put in place in other jurisdictions and so really really, it did land with us around two years ago when when Chats GPT hit the news. And Dan and his team, I think, took a really good way forward in starting to think around how we would mitigate the risk and the equity for our young people. Because as you just mentioned, Dan, our system is very big. And it's not a 2000 student school, we're talking about hundreds of thousands of students. So what you do for one group, you're doing at scale. And so it was really Dan and his team that kind of started to think, look, we need to address this and how are we going to best do this. The department took a very cautious approach. And I'm glad that our executive guided us in doing that. We put some restrictions in place in terms of Chats GPT and large language models, our staff can actually access it, but the students could not. And that was based on the fact that when it first came out, it had an 18 plus age bracket for use on their own terms and conditions. So it gave us some time to think around what we were going to do, how it was going to be implemented, what was the best way of implementing it, what was going to be the support that was needed. And also in that time, the National Framework for AI came out. So Dan, did you want to add anything to that? Because it really was Dan's thinking. Well, I think I'd only started in the job like last July. So I've not even managed to a year in yet. I intend to stick around, don't worry. We started the team and the purpose of the team was trying to get some kind of AI product into production environment because we've been tinkering in education with AI in different places, but really nothing had mega landed. And it seemed like a really good opportunity because Chats GPT kind of burst onto the scenes. So we made a few proof of concepts that kind of show what an internal as your tenant version might look like, and start to play around with the things that we'd have to do to make it safe for students, start to harvest some of the data that you get from conversations and work out how we might be able to use it. I'm thinking, Dan, as you're starting to work on the project, and you're saying, Oh, well, we could solve lots of different things. You narrowed down to a tutor based focus, I'm assuming because the product's called EduChat, is it? Is that right? New South Wales EduChat? Yes. Yeah. So it's called New South Wales EduChat. There's two versions of it. Same interface, you log in as a staff member. It's pretty much like Chats GPT. The only difference is we've already done some of the meta prompting to say you're a New South Wales teacher. So you don't every time you use it, you have to type in, I'm a teacher in New South Wales. And then for students, the system really ties it down to being a tutor. In addition, we've got like a whole pile of other content safety filters and things in there. And then we're using like a range of models as well, in the background and switching between models at the best and most appropriately priced for the activity that the person is trying to perform. And that includes some retrieval augmentation models too, so we can bring in policy documents or bits of the syllabus as well. And that's really brought it together to make it very New South Wales specific. Right, that's brilliant, because I think there's a lot going on in the world of tutors at the moment. And I was talking to somebody who was at the recent ASU JSV conference, and they said that kind of AI floor was full of people having developed tutors. But having a tutor that is very specific for students within your area with your curriculum with your way of working is the real value that you're bringing. And the other thing I kind of wonder is, you would have been trying to push back the tide by restricting access to chat GPT. And at the same time, you'll know that you want to provide access to to a tutor. So, so that balance would have been forcing you to move faster, I'm guessing. It was, but also that, like I said, trial as well, I should we should point that out. At the moment, we're in 50 schools, we're just going from 16. But it will be ending in a month and a bit's time, and we'll stop to consider what do we do next. So the real purpose of the trial was to gather some data, find out what people are using it for how often they're using it, how good it is that the things they're trying to use it for, and then we can like navigate forwards from there. I think the point that we probably need to call out early on is that, that the questions here, these are not technical problems. They are deeply intertwined with curriculum and pedagogy, and the teaching drives the need, not the tech. Very concerned when I hear a lot of those conversations that I'm sure you have seen and read everything on social media, that it's the tech, you need this tech for this purpose. Well, you kind of don't. If you think around the profession of teaching, I've been teaching for 30, we've been in the education department for 30 years, that's a long time. But when you think around, I think back to when I first started teaching, when I went into those classrooms, what stimulus did I wanna use? What book did I wanna use? What passage did I wanna use? What photo did I wanna use for that lesson? Those issues around what to use for teaching and learning are still the same with AI. What are you going to use for student learning, for student needs, for student outcomes? And they are the fundamental questions that we've grappled with and will continue to grapple with. But our teachers and the profession will always rise to that because teachers are smart people and they know their students and they know how they learn and what they need. Mm. You're spot on there. We had a conversation with Leanne Cameron, one of our education podcast episodes, who was a lecturer for education in James Cook University. And she was saying that actually some of the AI technologies are actually gonna save the teaching profession from a lot of the drudgery and things and the administration burden of creating things like lesson plans and things. Because she's seen all the pre-service teachers and the fact that they get down very, very quickly and they get into the role for three years and then leave. I was an ex-teacher as well. I would have loved to just fire off some of those questions into New South Wales EduChat to say, give me a better way to teach Pythagoras or C rubm today. I've got a student in my class who's really struggling with this particular maths concept. Give me a different way to explain that visually or something like that. I can just see those amazing positives and those teachers really getting driven by this. Yeah, I think it's high risk. This is high risk. And Dan and I always point out, we're talking about the trajectory of students learning and then their life trajectory from what they learn. So these are not low stakes conversations to be had. And when you are in school for 40 weeks a year, you need to be making sure that what we provide our teachers and the profession is high quality. They're going to be able to use it for explicit teaching. It's not surface level busy work that are not deep educational experiences for young people. And making sure that what is produced is going to be accurate and correct, but having the human beside the AI is really important because you talk around writing a lesson plan on Pythagoras theory. I think we all saw what was released with that amazing video of that exact Pythagoras theorem being spoken to by the AI. And the question around that is, how do you know what is being produced by that AI is actually accurate? You still need that human beside the student, beside the young person to have a touch point, to make sure that what is being produced there either in that lesson plan or whatever it might be by AI is high quality and accurate, yeah. So we definitely don't want to take away the professional skills of the teacher. When we think about projects that we're seeing, it's like, how do you supplement them and help them? And that's the same in other professions as well. We see AI being used in legal and it's like, well, the lawyers know their stuff. AI is there to help. Let's not move all the decision-making away. But when you talk about the student, for example, and the teacher alongside the student, I guess one of the things that we can potentially do is start to scale out the support for a student because the human isn't there all of the time. Often when we're talking about where you apply AI and how you apply it, one of the benchmarks is, what is the performance of the best available human? And if you think about tutoring, in reality, the best available human isn't available in many cases. So I guess I'm thinking about your remote and rural students, Michelle, where they just don't have access to the same level of people, diversity, skills that might exist for an inner city student. Yeah, look, it's undeniable that the AI, I think we're talking about those tutoring programmes here and especially AI personalised tutoring, they offer benefits. but undeniable challenges. I think when AI, especially those large language models kind of landed, there's a flurry of noise and raising concerns around the integrity of student assessment, the speed of misinformation within the education context. We need to point out that what you've talked about there, Ray, so that AI-supported tech, it's not entirely new. We've had AI-powered platforms to assess student learning needs, practice opportunities, feedback loops, branching for quite some time. And so it's now just kind of been put on steroids. But I think it's really important to look at some of the really robust pieces of research and what we're seeing and hearing. I really draw closely on Leslie Lobel's work. She's the industry professor from the Center for Social Justice and Inclusion at the Paul Ramsey Foundation. She's done that good work on shaping AI and ed tech to tackle that learning divide. And she's seen through that research that adaptive tutoring systems used with humans do have an opportunity there to improve how students are learning. We're talking around the speed and the scale and the scope beyond just a search engine now. It's no longer, you know that, it's no longer a search engine. But again, it comes back to the fundamental issue is around using AI for student learning purposes alongside a teacher. Yeah, yeah, that's exactly right. And I love the way you've done this and the way you've thought about it. Obviously, you spent a lot of time basing this on research, thinking about the proper way to implement this. And Dan, from your point of view, when you look into this, you can see this problem or solution to a problem and this tool to pilot. It must be quite daunting to look at that and go, how are we going to implement this? And I suppose the questions I get asked all the time, there's a lot of people in the same position you were in like nine months ago where they're thinking, okay, how do I tackle this? Where do I start? And how do I actually frame this and start to kind of move forward? Can you give us a bit of an insight in how you then turn this kind of vision into a bit of a reality? Yeah, so I kind of all started with a proof of concept. We just literally wrapped Chachabity and Azure around a web interface and then just made that available to some people to start playing around with. Tinkered with the system prompt to get it to act like a virtual tutor just to start demonstrating it, getting some interest going. And then to be honest, a little bit of a leap of faith that we could do it too, because you've got to take that small risk to get to the next stage of a project. So once we got people interested in wanting to take part in it, we made it available to a few more people and got them to try and do things they shouldn't be doing in it. Because I think the biggest challenge about making it available to students, especially unattended outside of school hours is making it safe. And we learned a lot by getting people to tinker with it, trying to break it, how to prevent jailbreaking, making it stay on topic and not talk about non-education related things, all kinds of crazy filtering and sticking it, making it not produce outputs that are harmful as well. So we've got like a range of filters that make that up. And we kind of layered it, built it over time and move very slowly. Well, my version of slow, which is still quite fast, but very slowly bringing a few more and more people on slower and slower. And so two are much more confident about the safety of it. So from a filter's point of view, we've obviously changed the system prompt like everyone does with these things. We've got one system prompt that is specialized for staff, one for students. And the student one is quite long, restricts it down to acting like this Socratic virtual tutor, but still allows students to ask for feedback on things. One of our early experiments, we had it so tied down that if you asked for feedback, it would enter into a Socratic conversation about the feedback rather than being helpful. So it's finding a balance of that. And we've developed a custom jailbreak filter. So we do that by staying up to date with all the jailbreaks that are published. So we've got someone in my team, Charles read it every week, looking for the latest jailbreaks. And then we work out some of the phrases in those that could be utilized in future jailbreaks as well. So that's how we're filtering that out. Then we're doing profanity filtering, which is actually a great project. We started just doing profanity filtering in English, then worked out our kids are smart. They're gonna like put asterisks in to replace words. So we should probably pad out all of these, the profanity words with weird characters. or extra vowels and all these common ways. Then we realized, ah, there's more than swearing than just in English. And our students speak a lot of languages. In our trial schools, I think we identified that they're from a hundred different languages they speak at home. So we engaged some translators to start making profanity word lists for us in different languages. That in itself was a procurement challenge because it turns out it's a bit of an unusual request to ask a translator just to give you a list of all the swear words in their language. And when we got them back, we were like, ah, now how do we know that these swear words are not also going to be used in normal conversations as well? So there's actually very complicated data science tasks. It took us about a month to come up with that list, but we now do profanity filtering in hundreds of languages. It's not enough, though, if we were going to do this, so we need to expand that even more. You mentioned the language side of it then, so in terms of equity and inclusion and things. So students from multi-linguistic backgrounds can actually interact with that new software inside your chat as well. Wow. Absolutely, yeah. So the underlying models we're using at the moment are ChantGPT Turbo and GPT-4 Turbo. Both of them like super good languages, fluent in at least 50, but conversational in like 1,000. And that algorithm, that multi-lingual requirement and choosing the algorithm is actually quite important. When you look at a lot of the more affordable open source ones that you could host yourself, most of them are English first, maybe Spanish is an add-on, like the second most popular language, but they're not multi-lingual enough to work in Australia with the selection of languages that we have in our schools. So that jailbreak prevention list I mentioned, we also translate that into hundreds of languages too, because we worked out, I'm pretty sure everyone knows this already, hopefully not revealing anything, that if you take a English jailbreak, you can translate it into any language and it still performs the same. And then you can translate it back out again on the other end. So we do all of that. We're also using Azure Content Safety Filter, which is like a semantic content filter. So instead of filtering on keywords, it understands the theme of the output and the input. And that helps us restrict sexual content, violence, hate speech, and self-harm. And we run that same semantic filter on the output and the profanity filtering on the output just for an abundance of caution, because we know the first thing people are gonna wanna do is trying to make a LLM swear. So we've put like that on the end as a way for us to detect should everything else fail, let's zoom in on that pretty quickly. So far it's like touch of wood. It's been perfect, but I think we needed all of those layers to work because frequently things slip through a layer, but the other layers prevent that. And then red teaming, like we do a huge amount of red teaming, both internal and we've hired several firms now to red team the combination. Every time you make a substantial change to the algorithm mix, or we tweak one of those filter layers, we red team that whole thing again. So we're continuously ourselves trying to break it. But of course we've got the best red team in the world. That's all of us. 800,000 of them. Using it continuously, yeah. So they certainly keep us on our toes. Thinking about that as well, the one other question I get asked all the time is obviously scale here. And I know you're in a pilot. Do you have a sense of how much volume of traffic students are generating using generative AI or staff are generating? Because obviously I suppose the other question is the staff need to be trained on prompting. And when I'm in schools at the minute, I'm finding that some staff and adults generally in the population know to prompt, some don't, some have got no idea. So I suppose you had to put some training in there, but then do you have thought about the scale and how that would work? I had initial thoughts. So when we were first setting up, so like how much compute do we need to run this? When we have absolutely no idea. So we, and also because you have to cater for the worst possible minutes, all those tokens arriving to be inferenced at the same time. And I had visions, like several classes in schools, the teacher going, okay, now you do it. And suddenly getting multiple sets of classes of 30 students all typing in a prompt at the same time. So we scaled for that worst case scenario, which turns out a crazy overestimate. I mean, it's nowhere near that bad. It's a lot more natural and flat during the day, which is great. And now we've got some great data for scaling. One of the things we wanted to do early on though, is not just use GPT-4 filling. I think it's like a, if you're a small organization, great solution, but a million people, potentially 800,000 students and 200,000 staff, we can't just be giving GPT-4 to everyone because it's too expensive. GPT-4. Last week was 20 times the cost of chance GPT per token. This week for GPT-4, it was now only 10 times, but still that adds a whole factor on to any scaling options we come up with. So we're using, and we're calling it an orchestrator, but it's basically a classifier model. And that detects the probability of a conversation coming through, being from maths, physics or chemistry. If it's maths, physics or chemistry, we send those conversations to GPT-4 because we know we need the power of GPT-4 for those conversations. And everything else we send through is chat GPT, so anything like English summarization or changing the complexity of a sentence or translations, that all goes through chat GPT. And our plan is to just continuously grow that selection of models in the middle, picking the best model for the best job. It's also a bit of a strategy for reducing the cognitive load on teachers. Well, can you imagine what it's like right now? It's hard enough for me and my job is AI, but a teacher whose job it is to teach is getting flooded with AI ed tech right now. How are they supposed to choose which one is the best for them? So we've taken it out of their hands. We've got a benchmark of about 1400 questions from across subjects that students learn in schools and we test every model that comes through. And that's how we knew that we needed to switch to maths, physics and chemistry for GPT-4. We found that they were the worst subjects we were benchmarking on the chat GPT model. So Dan, I just want to take you back a little bit through that journey that you just described, because I guess let's start with the starting point, which is, well, why not just give everybody chat GPT directly? So I think there's two things here that I think you've talked about. The first is system prompt, and I'm not sure if we've used the word system prompt on the podcast before, so let's just tear that one apart. So the system prompt, my understanding, and you're going to correct me, my understanding is basically that's the instructions you give it before it starts talking to you. And I'm guessing it's something like, hey, you're a tutor, whatever you do, don't answer the question, lead the student to the answer. Exactly. Right. Okay. So it's a set of ground rules for the conversation, and I'm guessing it's also written almost in the same way that you would actually talk to a human. Yes. It's a bit weird. I feel like we've gone in the space of a year from coding computers by writing code to now doing a weird combination of code plus English. It's very strange. Yeah. So it's almost like a reasoning conversation. When you're testing to make sure it's correct, it's about amending those sentences to be very clear about exactly what you want versus not. It's really similar to training someone new in your team to do something, like working with them side by side until you've got the instructions perfectly clear. The example I use all the time with people is treat it like an intern. Yeah, exactly. It comes back with an answer. You obviously check the answer that an intern gives you, and then you nudge and guide and steer. So that's your system prompt is that kind of advice. And then what you're doing is you're adding some filters on top because somebody would say, yeah, but what about swearing? Or what about the jailbreaks? What about they try and get it to do something it shouldn't? So you're basically answering each of those questions by adding a filtering layer between the user and the model to make sure that nothing bad, or you mitigate the risks of that. Yeah, and some of those filters are pretty simple. They're just like word matching. If a swear word comes through, we just block the conversation before it even gets to the model. Some of them are complicated, like there's your content safety filter we're using as an AI model itself that detects the probability of themes of conversation. But all that happened, the crazy part is all of that happens so fast, you don't even notice it in the conversation. We've got about five layers filtering every single conversation. So it's incredibly fast. Putting my hat on with audits and stuff like that, do you also have an ability to be able to go back through and check what Dan's been doing in case there's any issues? We are recording all the conversations, but it's not for monitoring purposes and that kind of individual layer level. To run this, we've obviously bought a pile of compute to cope with our peak moments, which are like six hours a day of school, but that gives us also a pile of compute outside of school hours to play with. So what we're doing is getting those same large language models to review the conversations that have happened during the day and extract the key themes. So we might say, oh, this teacher was using it for lesson playing, or this student was interested in terracotta warriors. And we summarise that up every night, so every morning when I connect up, I can say, what have all the conversations been about, like thematic themes during the day? And that's really helping us with the evaluation, so we can see what are the popular things that staff and students are using it for. And so, as you've built all of those things, you're learning a huge amount. And I've seen that you're really good at communicating as a team what's going on. I love some of the stuff you put on the web about how you've built this and all those kind of things. But as I was listening to you talking about the profanity filtering, the jailbreaking, the red team, and all those things that you learn, are you learning those things just Or do you think there's a world in which you start to share all of that valuable stuff with other educators and other education systems that aren't quite as big as yours? I would love that. I'm actually in regular contact with all the teams around, pretty much around the world actually, doing something similar. And we're all building very similar stuff. So we're always swapping notes anyway. But yes, it does seem that it would make sense for there to be a common resource. So, Ray, I think to that point, this work comes out of the Australian framework, is very heavily guided from the Australian framework for generative AI in schools. And so there is a work plan being developed. And one of those work plans is collaboration between jurisdictions, better sharing. Obviously, that then mitigates duplication of work, duplication of thinking. And I think that policymakers have done, and our executive in particular, have done a really, really good job of that, in aligning that thinking to that framework. Because otherwise, it just suddenly, you've asked the question, how did you come up with it? It's not just someone's good idea. It's been guided by an overarching policy umbrella. And again, that's what I'm sure Dan would agree. I see a lot of that type of thing, where it's just someone's good idea to go and do something within a system or within a school or within a context. And so having an overarching guide, it means that we can have some pillars. It's not just Dan and myself. There are pillars that are across the department. This is, like I said before, not a tech issue. So we've got people that are working on the safe gen I part of it. So we've got the capability of gen I, that uplift. That's some of the work that my team and I are guiding, and myself are guiding. We're looking at the teaching and learning part of generative AI. There's the compliance part. There's the generative AI enablement piece. So the implementation of secure AI applications moving into the future. I think it's really important that the work Dan and the team have done is a point in time. It may not need to be like that in two, three, five years' time. So I think our executives have been very forward thinking in the way they are putting this work together and the planning for this work out of that Australian framework as the initial document. We should talk a bit about the team. I think that's one of the things that has made this project very different to any other IT-type projects I've worked on. I have a super amazing team. Love them, dearly. Big shout out to you guys. But it's not just the tech team. There's a similar team in Michelle's area who are focusing on the education part. And in our chief data office, we've got a team focusing on ethics and responsible use of AI. And we meet like almost every single day. It's been an incredibly close-knit team. And I think you need that to make a good product that actually works for your customer, in our case, the teachers and students. Yeah, that's interesting because one of the things I was thinking as you're talking there is like, you know, I'm not trying to preempt the next iteration of this, but I suppose when you've got a generic tutor in the classroom which can support you with your curriculum, you know, that is amazing. And that's like the only grade. But then I suppose there's another element to that in your role as well, Dan, or your previous role doing the principal data ingestion stuff from the data platform. If you can correlate those two things together and know that Ray is a student who is struggling with maths or is really interested in soccer, then when you're giving them examples about Pythagoras again, you can talk about the way Lionel Messi crosses the ball or something. So I suppose there's another element to you of connecting the dots. So your team, working on the same team as the data team, is it bringing more facets to that. Yeah, definitely. And I think I'm excited about the virtual tutors. Pretty cool. But if we get to continue, the next phase of this is what are we going to do with this conversation data? If we get every single student using it every single day, it could be the largest data set of student progress we've ever had. And what we can do with that is going to be incredibly powerful. But as a data scientist without an education background, it would be pretty hard for me to come up with something. is really good. So we're totally reliant on Michelle and her team to tell us what it is that would be interesting to find in the data, and then we will make it. And also interesting to find in the data, but also back to Dan's point, we've got a professional learning suite. I think it's important, Dan, you mentioned earlier on in the podcast, teachers need to know some fundamentals around AI, what it can do, what it can't do, and what are some of the chronic problems with AI, what are some of the risks around this work? And so we're developing a comprehensive suite of professional learning, and there's some small, sharp modules that teachers and school leaders can opt into, and also workshop. So yeah, it's the full suite of support that we want to give our profession. That's amazing. I'm going to hone in on the if thing you said there, Dan, about if it continues, because I think back to the digital education revolution. What was that about 12 years ago in Australia? And the digital education revolution was a project that handed out devices to senior school students. And the metric of success was had they given away enough devices to the school? That was the metric of success. It wasn't about have we changed learning? It was have we shipped enough computers out to the schools? And the fact they were sitting there in boxes in the hall didn't matter. We'd hit the goal. So how do we measure, or how do you measure the education outcomes of the project? Because I guess that's going to be a huge factor in the if future question. I'm just going to say Dan may not be aware of that because he probably wasn't around during that time, but the DER was a federally government funded project. And again, I think well-meaning, but it comes back to what we discussed earlier. The tech was driving what was going on. Ray, you've just said it. How many devices landed in a school? I think there's been a lot of water under the bridge since that time. And gee, we've learned a lot because again, it comes down to now working really closely with the profession itself around what they need. And Dan started to talk around this. We can actually look at, this is a trial. This is a pilot, if you like. And we can look at how the teachers are using it, when, for what, in what ways to inform what happens next. Rather than doing it to the profession, we're doing things with the profession with an evidence base on why we are doing things. And again, with that policy advice over the top with the framework. I would like to say, Ray, those days are over because I think governments and systems have become far wiser in the way that we work with what's needed and the evidence base and the data before we would jump in and do something like that again. Dan, have I missed anything there? I don't think so, but it won't surprise you to know we're using data to measure the success and we're being very specific about what it is we're trying to measure right now. And I guess the fact that you're doing it as a pilot and you're not giving it to everybody, you're giving it to a group, it's reflective of that approach. It's not about integrating the technology into our teaching practice. I think it's around how we critically assess the impact of that on learning outcomes and student engagement. And we can start to look at those things in some of this work and through the pilot. So I think that's using tools to enhance and understand the major focus that is teaching and learning is the keys to the kingdom here. And Dan and I often talk about equity when it comes to AI because some students have access to the GPT-4 latest and some have the free version and there's 10 or 100 times difference in performance between them. I mean, one of the things you're doing is really addressing that equity piece. Yeah, so we're purposely trying to stay higher accuracy and free to use Gen AI. So if you go onto our website for any software you see our latest benchmark, I think right now we're about 20% more accurate than popular free to use AI products. And we're doing that by mixing those models up. So out mixing to GPT-4 when we need to, potentially even in the future down mixing for lower tasks just to keep that affordability because the more we down mix, the more we can afford to up mix other subjects. And then of course, injecting that in documents, which provides facts back in and reduces that risk of hallucination. So through that combination, we can keep accuracy high. And I think it's a weird factor of IT systems. Normally equity was about have and have not and now it's about quality of IT actually makes an impact. Whereas before like having a faster laptop probably wouldn't have had much of an impact on equity, but now definitely having a more accurate model does, so it's certainly an aspect of equity that we're focusing on in our team to make sure everyone has the same level and it's better than what you get for free. And it's compelling, Ray. It's a compelling need of the idea that some students have something and some don't, especially if they're at home and they have access to a paid version. And our job is to actually enable, when they come into school, that they have access to all the products that Dan and his team have. And so, yeah, it is absolutely an equity piece. And I'm originally from rural and remote areas. I grew up there. I went to a public school. My family is still there. My nephews and nieces are in regional New South Wales in government schools. And it's important that what is available to students in metropolitan areas is then afforded to students in rural and remote areas too. That equity piece is really a lens that I know Dan and his team have a passion for and has been one of the guiding lights in what he has been doing with that team. It is pretty amazing to see, being in Australia, and seeing the different equity issues that appear between independent schools, public schools, Catholic schools, and then seeing a department of your scale being able to actually really make a difference is actually really heartwarming and phenomenal, really, because you can actually do this at scale. Honestly, thank you both for the work you're doing with this for public education and equity in New South Wales. It is a large state, like you said at the beginning. There's a variety of communities. We serve a variety of people that land here and make Australia home, including myself and Ray and yourself, and people from rural and remote communities like yourself, Michelle. And it's something that is definitely an equity issue that we need to resolve and support every single student to get the best outcomes wherever they be in the state, I suppose. So it's amazing what you've done with this pilot. And I really hope, when does the pilot finish? Did you say next month, Dan? Yes, end of next month. Wow. Well, fingers and toes crossed with everything for that. And I'm really excited to see what's next. How are you, Ray? I'm also excited about the information that we've just talked about, and then the information that I know you've published about what you've been learning along the journey. So one of the things that I'm going to pay some concentration to this week is writing good show notes, because I think you've published a lot of really good information that people can go and read to dig down further into the detail. So, yeah, let's make sure that we provide more information for people to go and learn things, because even that context, I've not heard it before, the red teaming thing. I've heard it in the context of cyber. I've heard it in the context of AI outside of education. But I think you might be one of the first groups doing that work. And that's really good. And just that clarity of your process, and the filters that you've built on top of what is a standard language model, is going to be really useful for other people to be able to copy slash plagiarize slash get chat GPT to rewrite into their own version. Thank you. Thank you. Thanks. Thanks so much. 